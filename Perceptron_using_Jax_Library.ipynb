{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron using Jax Library.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIM1FkCfx24QNk5myEoyJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebzkurt1/ml_with_jax/blob/main/Perceptron_using_Jax_Library.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_76hMwb1wICX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "from jax import random\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X = jnp.array([[3.0,1.2,3.6],[1.4,6.21,6.8],[1.4,67.3,8.9],[1.4,2.6,1.6]])\n",
        "X = random.normal(key=random.PRNGKey(42),shape=(10,4))\n",
        "# y = jnp.array([[1],[2],[3],[2]])\n",
        "y = jnp.array(\n",
        "    [\n",
        "     [0],[0],[2],[1],[2],[0],[1],[2],[2],[1]\n",
        "    ]\n",
        ")\n",
        "class_num = 3\n",
        "# W = random.normal(key=random.PRNGKey(42),shape=(X.shape[-1],class_num))\n",
        "# b = random.normal(key=random.PRNGKey(42),shape=(class_num,1))\n",
        "# print(b)\n",
        "# print(jnp.matmul(X,W))\n",
        "# ff = (jnp.matmul(X,W).T + b).T\n",
        "# pred = jnp.exp(ff)/jnp.exp(ff).sum(axis=0)\n",
        "# pred_arg = jnp.argmax(pred,axis=1).reshape(-1,1)\n",
        "# print(pred_arg)"
      ],
      "metadata": {
        "id": "gcmnIU4h2Rwc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_sigmoid(matrix):\n",
        "    return (1/(1+jnp.exp(-matrix)))\n",
        "\n",
        "def custom_softmax(matrix):\n",
        "    return jnp.exp(matrix)/jnp.sum(jnp.exp(matrix),axis=1).reshape(-1,1)\n",
        "\n",
        "def forward_pass(X, W, b, activation):\n",
        "    return activation((jnp.matmul(X, W).T + b).T)\n",
        "\n",
        "def categorical_cross_entropy(yhat,y):\n",
        "    return -jnp.sum(y*jnp.log(yhat))\n",
        "\n",
        "# def feed_forward(X, Y, W, b, activation):\n",
        "#     Yhat = forward_pass(X,W,b)\n",
        "#     Yhat = activation(Yhat)\n",
        "#     categorical_pred = (jnp.argmax(Yhat,axis=1) + 1).reshape(-1,1)\n",
        "#     return categorical_pred\n",
        "\n",
        "def loss(X,Y,W,b,loss_fnc, activation):\n",
        "    Yhat = forward_pass(X,W,b,activation)\n",
        "    return loss_fnc(Yhat,Y)\n",
        "\n",
        "fwd = forward_pass(X,W,b,custom_softmax)\n",
        "act = custom_softmax(fwd)\n",
        "prd = (jnp.argmax(act,axis=1)+1).reshape(-1,1)\n",
        "lss = categorical_cross_entropy(prd,y)\n",
        "# ff = feed_forward(X,y,W,b,custom_softmax)\n",
        "# print((categorical_cross_entropy(ff,y)))\n",
        "\n",
        "W_grad = grad(loss,argnums=2)(X,y,W,b,categorical_cross_entropy,custom_softmax)\n",
        "print('W_grad', W_grad)\n",
        "b_grad = grad(loss,argnums=3)(X,y,W,b,categorical_cross_entropy,custom_softmax)\n",
        "print(\"b_grad\",b_grad)"
      ],
      "metadata": {
        "id": "qgWs6IWxIJMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78508c31-d723-42ef-917f-888d82e0fe97"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_grad [[ 8.03366   -5.8095484 -2.2241096]\n",
            " [ 6.8415346 -6.1532435 -0.6882926]\n",
            " [10.902298  -3.7077832 -7.194514 ]\n",
            " [-2.7530346  3.1355824 -0.3825494]]\n",
            "b_grad [[10.114142 ]\n",
            " [-1.3245295]\n",
            " [-8.789612 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, class_num=1, activation_func='sigmoid', loss_func='mean_squared_error', learning_rate=0.01, iter=50, random_key=1):\n",
        "        self.class_num = class_num\n",
        "        self.activation_func = activation_func\n",
        "        self.loss_func = loss_func\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iter = iter\n",
        "        self.random_key = random.PRNGKey(random_key)\n",
        "\n",
        "    def initialize_weights(self, X):\n",
        "        self.W = random.normal(\n",
        "            key=self.random_key,\n",
        "            shape=(X.shape[-1],self.class_num)\n",
        "        )\n",
        "        self.b = random.normal(\n",
        "            key=self.random_key,\n",
        "            shape=(self.class_num,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return (jnp.matmul(X, self.W).T + self.b).T\n",
        "\n",
        "    def softmax_func(self, matrix):\n",
        "        return jnp.exp(matrix)/jnp.sum(jnp.exp(matrix),axis=1).reshape(-1,1)\n",
        "\n",
        "    def sigmoid_func(self, matrix):\n",
        "        return (1/(1+jnp.exp(-matrix)))\n",
        "\n",
        "    def jax_sigmoid(self, matrix):\n",
        "        return jax.nn.sigmoid(matrix)\n",
        "    \n",
        "    def mean_squared_error(self, Yhat, Y):\n",
        "        return jnp.mean((Yhat-Y)**2)\n",
        "        \n",
        "    def categorical_cross_entropy(self, Yhat, Y):\n",
        "        return -jnp.sum(Y*jnp.log(Yhat))\n",
        "    \n",
        "    def forward_step(self, X, W, b):\n",
        "        if self.activation_func == 'sigmoid':\n",
        "            return self.sigmoid_func((jnp.matmul(X, W).T + b).T)\n",
        "        elif self.activation_func == 'softmax':\n",
        "            # print(\"IN FORWARD \\n\",((jnp.matmul(X, W).T + b).T))\n",
        "            print(\"WITH THE SOFT \\n\",jax.nn.softmax((jnp.matmul(X, W).T + b).T))\n",
        "            # return self.softmax_func((jnp.matmul(X, W).T + b).T)\n",
        "            return jax.nn.softmax((jnp.matmul(X, W).T + b).T)\n",
        "        else:\n",
        "            return (jnp.matmul(X, W).T + b).T\n",
        "    \n",
        "    def loss(self, X, Y, W, b):\n",
        "        # print(X.shape,Y.shape,W.shape,b.shape)\n",
        "        Yhat = self.forward_step(X,W,b)\n",
        "        # print(\"In loss function \\n\",Yhat)\n",
        "        if self.loss_func == 'mean_squared_error':\n",
        "            return self.mean_squared_error(Yhat, Y)\n",
        "        elif self.loss_func == 'categorical_cross_entropy':\n",
        "            return self.categorical_cross_entropy(Yhat,Y)\n",
        "\n",
        "    def param_update(self, w_gradient, b_gradient):\n",
        "        self.W -= self.learning_rate * w_gradient\n",
        "        self.b -= self.learning_rate * b_gradient\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return jnp.argmax(self.forward_step(X,self.W,self.b),axis=1)\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        self.history = {\n",
        "            'loss':[],\n",
        "            'accuracy':[]\n",
        "        }\n",
        "        self.initialize_weights(X)\n",
        "        for i in range(self.iter):\n",
        "            # print(X,Y,self.W,self.b)\n",
        "            step_loss = self.loss(X, Y, self.W, self.b)\n",
        "            # print(step_loss)\n",
        "            step_prediction = self.predict(X).reshape(-1,1)\n",
        "            step_accuracy = (((step_prediction==Y).sum())/X.shape[0])*100\n",
        "            self.history['accuracy'].append(step_accuracy)\n",
        "            self.history['loss'].append(step_loss)\n",
        "            W_grad = grad(self.loss,argnums=2)(X,Y,self.W,self.b)\n",
        "            b_grad = grad(self.loss,argnums=3)(X,Y,self.W,self.b)\n",
        "            self.param_update(W_grad,b_grad)\n",
        "            print(\"Epoch\",i,\"accuracy :\",step_accuracy)\n",
        "            # print(step_loss)\n",
        "            # print(W_grad)\n",
        "            # print(b_grad)\n",
        "            # print(self.W)\n",
        "        return self.history"
      ],
      "metadata": {
        "id": "y8qZiC_MwKYr"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron_model = Perceptron(\n",
        "    class_num=class_num,\n",
        "    activation_func='softmax',\n",
        "    loss_func='categorical_cross_entropy',\n",
        ")"
      ],
      "metadata": {
        "id": "B04pMvXzjJXT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = perceptron_model.fit(X,y)\n",
        "plt.plot(model_history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "hf7Kl0r4kbGL",
        "outputId": "783e84a8-775d-4285-868a-cb828db438e3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f273b1d70d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtUwhIqsm7Kz",
        "outputId": "4735e16e-8310-4a71-e812-f78af674a273"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train X shapes : \", train_X.shape, type(train_X))\n",
        "print(\"Train Y shapes : \", train_Y.shape, type(train_Y))\n",
        "print(\"Test X shapes : \", test_X.shape, type(test_X))\n",
        "print(\"Test Y shapes : \", test_Y.shape, type(test_Y))\n",
        "\n",
        "flat_train_X = jnp.asarray(train_X).reshape(-1,28*28)\n",
        "flat_norm_train_X = flat_train_X/255.0\n",
        "flat_train_Y = jnp.asarray(train_Y).reshape(-1,1)\n",
        "\n",
        "\n",
        "flat_test_X = jnp.asarray(test_X).reshape(-1,28*28)\n",
        "flat_norm_test_X = flat_test_X/255.0\n",
        "flat_test_Y = jnp.asarray(test_Y).reshape(-1,1)\n",
        "\n",
        "print(\"Processed Train X shapes : \", flat_norm_train_X.shape, type(flat_norm_train_X))\n",
        "print(\"Processed Train Y shapes : \", flat_train_Y.shape, type(flat_train_Y))\n",
        "print(\"Processed Test X shapes : \", flat_norm_test_X.shape, type(flat_norm_test_X))\n",
        "print(\"Processed Test Y shapes : \", flat_test_Y.shape, type(flat_test_Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHXh70ZZnT4r",
        "outputId": "3e59b405-63b0-4335-d8ba-257200b54e1f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X shapes :  (60000, 28, 28) <class 'numpy.ndarray'>\n",
            "Train Y shapes :  (60000,) <class 'numpy.ndarray'>\n",
            "Test X shapes :  (10000, 28, 28) <class 'numpy.ndarray'>\n",
            "Test Y shapes :  (10000,) <class 'numpy.ndarray'>\n",
            "Processed Train X shapes :  (60000, 784) <class 'jaxlib.xla_extension.DeviceArray'>\n",
            "Processed Train Y shapes :  (60000, 1) <class 'jaxlib.xla_extension.DeviceArray'>\n",
            "Processed Test X shapes :  (10000, 784) <class 'jaxlib.xla_extension.DeviceArray'>\n",
            "Processed Test Y shapes :  (10000, 1) <class 'jaxlib.xla_extension.DeviceArray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_perceptron_model = Perceptron(\n",
        "    class_num=10,\n",
        "    activation_func='softmax',\n",
        "    loss_func='categorical_cross_entropy',\n",
        "    iter=3\n",
        ")"
      ],
      "metadata": {
        "id": "4eIDePdoteRX"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_history = mnist_perceptron_model.fit(flat_norm_train_X,flat_train_Y)\n",
        "plt.plot(model_history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QaUGaWvVnnQy",
        "outputId": "e4e82a6b-5dfc-4317-a4fe-e99da654b092"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITH THE SOFT \n",
            " [[6.41975999e-02 7.72180375e-14 4.40844923e-01 ... 7.25509149e-12\n",
            "  3.33175086e-03 2.19234789e-06]\n",
            " [1.12821253e-05 4.41953924e-15 2.73078695e-12 ... 1.67155872e-12\n",
            "  5.13250828e-02 4.23662883e-09]\n",
            " [5.91588056e-10 1.31975125e-11 4.27631810e-16 ... 7.81825861e-07\n",
            "  2.30332850e-10 2.73715359e-05]\n",
            " ...\n",
            " [1.20018827e-04 6.17792661e-09 3.30750964e-07 ... 4.33711648e-05\n",
            "  1.53182792e-02 2.73711365e-08]\n",
            " [3.71682213e-10 4.85025253e-16 5.07619077e-12 ... 6.21370873e-07\n",
            "  2.71865545e-04 4.64026018e-09]\n",
            " [2.05249432e-13 1.14529432e-15 2.50863080e-10 ... 6.78584272e-11\n",
            "  1.15804432e-04 2.59300936e-08]]\n",
            "WITH THE SOFT \n",
            " [[6.41975999e-02 7.72180375e-14 4.40844923e-01 ... 7.25509149e-12\n",
            "  3.33175086e-03 2.19234789e-06]\n",
            " [1.12821253e-05 4.41953924e-15 2.73078695e-12 ... 1.67155872e-12\n",
            "  5.13250828e-02 4.23662883e-09]\n",
            " [5.91588056e-10 1.31975125e-11 4.27631810e-16 ... 7.81825861e-07\n",
            "  2.30332850e-10 2.73715359e-05]\n",
            " ...\n",
            " [1.20018827e-04 6.17792661e-09 3.30750964e-07 ... 4.33711648e-05\n",
            "  1.53182792e-02 2.73711365e-08]\n",
            " [3.71682213e-10 4.85025253e-16 5.07619077e-12 ... 6.21370873e-07\n",
            "  2.71865545e-04 4.64026018e-09]\n",
            " [2.05249432e-13 1.14529432e-15 2.50863080e-10 ... 6.78584272e-11\n",
            "  1.15804432e-04 2.59300936e-08]]\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[6.41975999e-02 7.72180375e-14 4.40844923e-01 ... 7.25509149e-12\n",
            "  3.33175086e-03 2.19234789e-06]\n",
            " [1.12821253e-05 4.41953924e-15 2.73078695e-12 ... 1.67155872e-12\n",
            "  5.13250828e-02 4.23662883e-09]\n",
            " [5.91588056e-10 1.31975125e-11 4.27631810e-16 ... 7.81825861e-07\n",
            "  2.30332850e-10 2.73715359e-05]\n",
            " ...\n",
            " [1.20018827e-04 6.17792661e-09 3.30750964e-07 ... 4.33711648e-05\n",
            "  1.53182792e-02 2.73711365e-08]\n",
            " [3.71682213e-10 4.85025253e-16 5.07619077e-12 ... 6.21370873e-07\n",
            "  2.71865545e-04 4.64026018e-09]\n",
            " [2.05249432e-13 1.14529432e-15 2.50863080e-10 ... 6.78584272e-11\n",
            "  1.15804432e-04 2.59300936e-08]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[6.41975999e-02, 7.72180375e-14, 4.40844923e-01, ...,\n",
            "              7.25509149e-12, 3.33175086e-03, 2.19234789e-06],\n",
            "             [1.12821253e-05, 4.41953924e-15, 2.73078695e-12, ...,\n",
            "              1.67155872e-12, 5.13250828e-02, 4.23662883e-09],\n",
            "             [5.91588056e-10, 1.31975125e-11, 4.27631810e-16, ...,\n",
            "              7.81825861e-07, 2.30332850e-10, 2.73715359e-05],\n",
            "             ...,\n",
            "             [1.20018827e-04, 6.17792661e-09, 3.30750964e-07, ...,\n",
            "              4.33711648e-05, 1.53182792e-02, 2.73711365e-08],\n",
            "             [3.71682213e-10, 4.85025253e-16, 5.07619077e-12, ...,\n",
            "              6.21370873e-07, 2.71865545e-04, 4.64026018e-09],\n",
            "             [2.05249432e-13, 1.14529432e-15, 2.50863080e-10, ...,\n",
            "              6.78584272e-11, 1.15804432e-04, 2.59300936e-08]],            dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f0610>, invars=(Traced<ConcreteArray([[2.0423765]\n",
            " [1.0541203]\n",
            " [1.0000284]\n",
            " ...\n",
            " [1.0157268]\n",
            " [1.0002725]\n",
            " [1.0001187]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[1.31115675e-01 1.57708306e-13 9.00371313e-01 ... 1.48176280e-11\n",
            "  6.80468976e-03 4.47759976e-06]\n",
            " [1.18927173e-05 4.65872610e-15 2.87857780e-12 ... 1.76202390e-12\n",
            "  5.41028120e-02 4.46591653e-09]\n",
            " [5.91604821e-10 1.31978872e-11 4.27643933e-16 ... 7.81848030e-07\n",
            "  2.30339386e-10 2.73723126e-05]\n",
            " ...\n",
            " [1.21906342e-04 6.27508578e-09 3.35952620e-07 ... 4.40532567e-05\n",
            "  1.55591872e-02 2.78015975e-08]\n",
            " [3.71783493e-10 4.85157443e-16 5.07757421e-12 ... 6.21540210e-07\n",
            "  2.71939643e-04 4.64152494e-09]\n",
            " [2.05273800e-13 1.14543027e-15 2.50892862e-10 ... 6.78664833e-11\n",
            "  1.15818184e-04 2.59331721e-08]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[0.23973331]\n",
            " [0.89995265]\n",
            " [0.99994326]\n",
            " ...\n",
            " [0.9692731 ]\n",
            " [0.99945515]\n",
            " [0.9997626 ]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c84d0; to 'JaxprTracer' at 0x7f27382c8410>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27382ea070>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[6.41975999e-02 7.72180375e-14 4.40844923e-01 ... 7.25509149e-12\n",
            "  3.33175086e-03 2.19234789e-06]\n",
            " [1.12821253e-05 4.41953924e-15 2.73078695e-12 ... 1.67155872e-12\n",
            "  5.13250828e-02 4.23662883e-09]\n",
            " [5.91588056e-10 1.31975125e-11 4.27631810e-16 ... 7.81825861e-07\n",
            "  2.30332850e-10 2.73715359e-05]\n",
            " ...\n",
            " [1.20018827e-04 6.17792661e-09 3.30750964e-07 ... 4.33711648e-05\n",
            "  1.53182792e-02 2.73711365e-08]\n",
            " [3.71682213e-10 4.85025253e-16 5.07619077e-12 ... 6.21370873e-07\n",
            "  2.71865545e-04 4.64026018e-09]\n",
            " [2.05249432e-13 1.14529432e-15 2.50863080e-10 ... 6.78584272e-11\n",
            "  1.15804432e-04 2.59300936e-08]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[6.41975999e-02, 7.72180375e-14, 4.40844923e-01, ...,\n",
            "              7.25509149e-12, 3.33175086e-03, 2.19234789e-06],\n",
            "             [1.12821253e-05, 4.41953924e-15, 2.73078695e-12, ...,\n",
            "              1.67155872e-12, 5.13250828e-02, 4.23662883e-09],\n",
            "             [5.91588056e-10, 1.31975125e-11, 4.27631810e-16, ...,\n",
            "              7.81825861e-07, 2.30332850e-10, 2.73715359e-05],\n",
            "             ...,\n",
            "             [1.20018827e-04, 6.17792661e-09, 3.30750964e-07, ...,\n",
            "              4.33711648e-05, 1.53182792e-02, 2.73711365e-08],\n",
            "             [3.71682213e-10, 4.85025253e-16, 5.07619077e-12, ...,\n",
            "              6.21370873e-07, 2.71865545e-04, 4.64026018e-09],\n",
            "             [2.05249432e-13, 1.14529432e-15, 2.50863080e-10, ...,\n",
            "              6.78584272e-11, 1.15804432e-04, 2.59300936e-08]],            dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f0240>, invars=(Traced<ConcreteArray([[2.0423765]\n",
            " [1.0541203]\n",
            " [1.0000284]\n",
            " ...\n",
            " [1.0157268]\n",
            " [1.0002725]\n",
            " [1.0001187]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[1.31115675e-01 1.57708306e-13 9.00371313e-01 ... 1.48176280e-11\n",
            "  6.80468976e-03 4.47759976e-06]\n",
            " [1.18927173e-05 4.65872610e-15 2.87857780e-12 ... 1.76202390e-12\n",
            "  5.41028120e-02 4.46591653e-09]\n",
            " [5.91604821e-10 1.31978872e-11 4.27643933e-16 ... 7.81848030e-07\n",
            "  2.30339386e-10 2.73723126e-05]\n",
            " ...\n",
            " [1.21906342e-04 6.27508578e-09 3.35952620e-07 ... 4.40532567e-05\n",
            "  1.55591872e-02 2.78015975e-08]\n",
            " [3.71783493e-10 4.85157443e-16 5.07757421e-12 ... 6.21540210e-07\n",
            "  2.71939643e-04 4.64152494e-09]\n",
            " [2.05273800e-13 1.14543027e-15 2.50892862e-10 ... 6.78664833e-11\n",
            "  1.15818184e-04 2.59331721e-08]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[0.23973331]\n",
            " [0.89995265]\n",
            " [0.99994326]\n",
            " ...\n",
            " [0.9692731 ]\n",
            " [0.99945515]\n",
            " [0.9997626 ]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c8290; to 'JaxprTracer' at 0x7f27382c8410>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27382f05b0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "Epoch 0 accuracy : 8.281667\n",
            "WITH THE SOFT \n",
            " [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "WITH THE SOFT \n",
            " [[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             ...,\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f04f0>, invars=(Traced<ConcreteArray([[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c8770; to 'JaxprTracer' at 0x7f27382c86b0>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27382f0330>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             ...,\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.],\n",
            "             [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f0610>, invars=(Traced<ConcreteArray([[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " ...\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c8470; to 'JaxprTracer' at 0x7f27382c8650>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27382dd9b0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "Epoch 1 accuracy : 11.236667\n",
            "WITH THE SOFT \n",
            " [[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]]\n",
            "WITH THE SOFT \n",
            " [[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]]\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             ...,\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f0620>, invars=(Traced<ConcreteArray([[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " ...\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " ...\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c8830; to 'JaxprTracer' at 0x7f27382c8350>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27382f0ef0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "WITH THE SOFT \n",
            " Traced<ConcreteArray([[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]], dtype=float32)>with<JVPTrace(level=2/0)> with\n",
            "  primal = DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             ...,\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan],\n",
            "             [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)\n",
            "  tangent = Traced<ShapedArray(float32[60000,10])>with<JaxprTrace(level=1/0)> with\n",
            "    pval = (ShapedArray(float32[60000,10]), *)\n",
            "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x7f273b6f0340>, invars=(Traced<ConcreteArray([[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " ...\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " ...\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]\n",
            " [nan nan nan ... nan nan nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ConcreteArray([[nan]\n",
            " [nan]\n",
            " [nan]\n",
            " ...\n",
            " [nan]\n",
            " [nan]\n",
            " [nan]], dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,10]):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[60000,1]):JaxprTrace(level=1/0)>), outvars=[<weakref at 0x7f27382c81d0; to 'JaxprTracer' at 0x7f27382c89b0>], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(true_divide)', 'donated_invars': (False, False, False, False, False), 'inline': True, 'call_jaxpr': { lambda ; a:f32[60000,1] b:f32[60000,10] c:f32[60000,1] d:f32[60000,10] e:f32[60000,1]. let\n",
            "    f:f32[60000,10] = div d a\n",
            "    g:f32[60000,1] = neg e\n",
            "    h:f32[60000,10] = mul g b\n",
            "    i:f32[60000,10] = mul h c\n",
            "    j:f32[60000,10] = add_any f i\n",
            "  in (j,) }}, source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x7f27383d5df0>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
            "Epoch 2 accuracy : 9.871667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f273825ac90>]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_perceptron_model.W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Uyv8uOw7GL",
        "outputId": "2e0315b9-18f9-452f-96fd-751110637598"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
              "             [nan, nan, nan, ..., nan, nan, nan],\n",
              "             [nan, nan, nan, ..., nan, nan, nan],\n",
              "             ...,\n",
              "             [nan, nan, nan, ..., nan, nan, nan],\n",
              "             [nan, nan, nan, ..., nan, nan, nan],\n",
              "             [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    }
  ]
}